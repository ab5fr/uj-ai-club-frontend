{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"width: 100%; margin: 0; padding: 0;\">\n",
        "    <img src=\"https://i.postimg.cc/Bn4H8BrF/Header.png\"\n",
        "         style=\"width: 100vw;\n",
        "                position: relative;\n",
        "                left: 50%;\n",
        "                right: 50%;\n",
        "                margin-left: -50vw;\n",
        "                margin-right: -50vw;\n",
        "                display: block;\">\n",
        "</div>"
      ],
      "metadata": {
        "id": "SlbKF9Q9wXA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <h1 align=\"center\">üèõÔ∏è [ AI Club - University of Jeddah ] üèõÔ∏è</h1>\n",
        "\n",
        "# <h2 align=\"center\">Machine Learning Foundations: The Ultimate Challenge üèÜ</h2>\n",
        "### <h3 align=\"center\">Show Your Skills in Data Engineering & Analysis üöÄ</h3>\n",
        "\n",
        "---\n",
        "\n",
        "## üèÖ Final Grade\n",
        "# <h1 align=\"center\">____ / 20</h1>\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ The Mission\n",
        "Welcome to the Machine Learning Foundations Challenge! This notebook is designed to test your ability to handle real-world data. You will be working with the **Titanic Dataset** to clean, transform, and prepare it for a future ML model.\n",
        "\n",
        "### ‚ö†Ô∏è Instructions:\n",
        "1. Complete all tasks marked with **TODO**.\n",
        "2. Do not use external libraries other than **NumPy** and **Pandas**.\n",
        "3. Ensure your code is clean and well-commented.\n",
        "4. Submit your completed work as an (`.ipynb`) file.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8y5TXy4YvPoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **Section  1Ô∏è‚É£: NumPy Mastery Challenges (10 Tasks)** üî¢\n"
      ],
      "metadata": {
        "id": "OFtEhhGyzInL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 1: Custom Sequence & Mean**\n",
        "**Objective:** Create a 1D array containing **12** equally spaced numbers between **10** and **100** (inclusive). Then, calculate the **Mean** of this array."
      ],
      "metadata": {
        "id": "3N9Z4_Wi126i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# TODO: Create the array and calculate its mean\n",
        "arr_1 = None\n",
        "mean_val = None\n",
        "\n",
        "print(f\"Array: {arr_1}\")\n",
        "print(f\"Mean: {mean_val}\")"
      ],
      "metadata": {
        "id": "ful00xiavQAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 2: Reshaping & Attributes**\n",
        "**Objective:** Take the array from Task 1 and **Reshape** it into a matrix of **3 rows and 4 columns**. Print the **Shape** and **Size** of the new matrix."
      ],
      "metadata": {
        "id": "EBqdKeEd2C4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Reshape arr_1 to (3, 4) and check its attributes\n",
        "matrix_2 = None\n",
        "m_shape = None\n",
        "m_size = None\n",
        "\n",
        "print(f\"Matrix:\\n{matrix_2}\")\n",
        "print(f\"Shape: {m_shape}, Total Elements: {m_size}\")"
      ],
      "metadata": {
        "id": "v6sQgZu_0MuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 3: Feature Extraction (Column Slicing)**\n",
        "**Objective:** From the matrix created in Task 2, extract only the **Third Column** (index 2). In ML, this is how we isolate a specific \"Feature\" from our data."
      ],
      "metadata": {
        "id": "093vvDjB2uRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Slice the 3rd column from matrix_2\n",
        "feature_col = None\n",
        "\n",
        "print(f\"Extracted Column: {feature_col}\")"
      ],
      "metadata": {
        "id": "ByLQ_f0Y2rGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 4: Weight Initialization (Randomness)**\n",
        "**Objective:** Generate a **2x3** matrix filled with **Random Values** between 0 and 1. This simulates initializing weights for a small Neural Network."
      ],
      "metadata": {
        "id": "cc4Anda322Qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Generate 2x3 random matrix\n",
        "weights = None\n",
        "\n",
        "print(f\"Random Weights:\\n{weights}\")"
      ],
      "metadata": {
        "id": "5bBowNcn24OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 5: Identity Matrix & Scaling**\n",
        "**Objective:** Create a **4x4 Identity Matrix** and multiply it by **25** using **Broadcasting**."
      ],
      "metadata": {
        "id": "MsPBVTZ6264X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create 4x4 identity matrix and scale it\n",
        "scaled_identity = None\n",
        "\n",
        "print(f\"Scaled Identity Matrix:\\n{scaled_identity}\")"
      ],
      "metadata": {
        "id": "ylM0obg528wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 6: Boolean Masking (Filtering)**\n",
        "**Objective:** Given the array `[15, 42, 5, 89, 33, 12, 55]`, use **Boolean Indexing** to extract only the numbers **greater than 30**."
      ],
      "metadata": {
        "id": "gJMN-Rgf2_Kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([15, 42, 5, 89, 33, 12, 55])\n",
        "\n",
        "# TODO: Filter elements > 30\n",
        "filtered_data = None\n",
        "\n",
        "print(f\"Elements > 30: {filtered_data}\")"
      ],
      "metadata": {
        "id": "qUIC59d93ACu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 7: Conditional Logic (np.where)**\n",
        "**Objective:** Use `np.where` on the array from Task 6. If a value is **greater than 30**, replace it with the string **'High'**, otherwise replace it with **'Low'**."
      ],
      "metadata": {
        "id": "MABiHpu93By_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Apply np.where logic\n",
        "classified_data = None\n",
        "\n",
        "print(f\"Classified Data: {classified_data}\")"
      ],
      "metadata": {
        "id": "YghBTcBY3EDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 8: Finding Predictions (np.argmax)**\n",
        "**Objective:** Suppose a model outputted these probabilities for 4 classes: `[0.1, 0.7, 0.05, 0.15]`. Find the **Index** of the highest probability (the predicted class)."
      ],
      "metadata": {
        "id": "SJgec7no3IdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = np.array([0.1, 0.7, 0.05, 0.15])\n",
        "\n",
        "# TODO: Find index of maximum value\n",
        "predicted_class = None\n",
        "\n",
        "print(f\"Predicted Class Index: {predicted_class}\")"
      ],
      "metadata": {
        "id": "sk58KqlG3IwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 9: Matrix Transposition**\n",
        "**Objective:** Take the **2x3** `weights` matrix from Task 4 and **Transpose** it to become a **3x2** matrix."
      ],
      "metadata": {
        "id": "Hrtr2RUP3KnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Transpose the weights matrix\n",
        "transposed_weights = None\n",
        "\n",
        "print(f\"New Shape: {transposed_weights.shape}\")"
      ],
      "metadata": {
        "id": "5IYNLnAW3NNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 10: Image Flattening Simulation**\n",
        "**Objective:** Create a **2x2** matrix representing a tiny grayscale image. **Flatten** it into a **1D vector** to prepare it for a Fully Connected Layer."
      ],
      "metadata": {
        "id": "EJTFjy_f3P0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = np.array([[255, 128], [0, 64]])\n",
        "\n",
        "# TODO: Flatten the image matrix\n",
        "flattened_image = None\n",
        "\n",
        "print(f\"Flattened Vector: {flattened_image}\")"
      ],
      "metadata": {
        "id": "FrUILRY13QG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#  **Section 2Ô∏è‚É£: Pandas Data Engineering Challenge (10 Tasks)**üêº\n",
        "\n",
        "**Instructions:** Now we move to the heart of Data Science. You will work on the famous **Titanic Dataset**. Your goal is to clean, transform, and analyze this data using advanced Pandas techniques.\n",
        "\n",
        "**Key Skills Tested:**\n",
        "* Handling Missing Values & Duplicates.\n",
        "* Advanced Grouping & Aggregation.\n",
        "* Data Merging & Transformation."
      ],
      "metadata": {
        "id": "ppNlvyg13nHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Loading Titanic Dataset\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Intentionally adding some duplicates for the challenge\n",
        "df = pd.concat([df, df.iloc[:5]], ignore_index=True)\n",
        "\n",
        "print(\"‚úÖ Titanic Dataset Loaded with intentional duplicates and missing values.\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "wpFhK9Cw3nlD",
        "outputId": "b9fa0aa2-5f1c-49aa-f608-f96c1e2e9351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Titanic Dataset Loaded with intentional duplicates and missing values.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43738b07-26f6-4acd-8312-2429c1626b5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43738b07-26f6-4acd-8312-2429c1626b5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43738b07-26f6-4acd-8312-2429c1626b5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43738b07-26f6-4acd-8312-2429c1626b5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 896,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 258,\n        \"min\": 1,\n        \"max\": 891,\n        \"num_unique_values\": 891,\n        \"samples\": [\n          710,\n          440,\n          841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Moubarek, Master. Halim Gonios (\\\"William George\\\")\",\n          \"Kvillner, Mr. Johan Henrik Johannesson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.485350435490648,\n        \"min\": 0.42,\n        \"max\": 80.0,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.75,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SibSp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 681,\n        \"samples\": [\n          \"11774\",\n          \"248740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.59678782719657,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          11.2417,\n          51.8625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cabin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"D45\",\n          \"B49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"S\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 11: Missing Data Audit**\n",
        "**Objective:** Calculate the **Percentage** of missing values for each column. Sort the result in **descending order**. This helps identify which columns might need to be dropped."
      ],
      "metadata": {
        "id": "653i3T6J4CYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Calculate percentage of NaN per column\n",
        "missing_pct = None\n",
        "\n",
        "print(f\"Missing Data Percentage:\\n{missing_pct}\")"
      ],
      "metadata": {
        "id": "MMrs0imX39Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 12: Smart Imputation (Group-based Fillna)**\n",
        "**Objective:** Instead of filling missing `Age` values with a global mean, fill them with the **Median Age** of their respective **Gender** (`Sex`) group. This is a common practice in advanced feature engineering."
      ],
      "metadata": {
        "id": "z55sE2Sd4K5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fill NaN in 'Age' column using the median of each 'Sex' group\n",
        "# Hint: Use groupby and transform or apply\n",
        "df['Age'] = None\n",
        "\n",
        "print(f\"Remaining Nulls in Age: {df['Age'].isnull().sum()}\")"
      ],
      "metadata": {
        "id": "zL4S9UFd4Mrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 13: Data Integrity (Duplicates & Dropping)**\n",
        "**Objective:** 1. Identify and **Remove** all duplicate rows.\n",
        "2. **Drop** the `Cabin` column entirely because it has too many missing values (checked in Task 11)."
      ],
      "metadata": {
        "id": "Ver3PJ004U1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Remove duplicates and drop 'Cabin' column\n",
        "df_cleaned = None\n",
        "\n",
        "print(f\"Shape after cleaning: {df_cleaned.shape}\")"
      ],
      "metadata": {
        "id": "ezt9TZ0x4WFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 14: Complex Filtering (The Query Challenge)**\n",
        "**Objective:** Use the `.query()` method to extract a subset of passengers who:\n",
        "* Were in **1st Class** (`Pclass == 1`).\n",
        "* Were **Female**.\n",
        "* Had a **Fare** greater than the **average fare** of the entire dataset."
      ],
      "metadata": {
        "id": "bE93y-vS4YFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Use df.query() to find these specific passengers\n",
        "VIP_females = None\n",
        "\n",
        "print(f\"Count of VIP Females: {len(VIP_females)}\")"
      ],
      "metadata": {
        "id": "so3ePSZW4ZX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 15: Feature Engineering (Apply Logic)**\n",
        "**Objective:** Use `.apply()` with a **Lambda function** to create a new column called `Age_Group`.\n",
        "* If Age < 18 (Smaller than 18) -> 'Minor'.\n",
        "* If Age >= 18 (Greater than or equal 18) -> 'Adult'."
      ],
      "metadata": {
        "id": "0wkytbps4hYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create 'Age_Group' column using apply\n",
        "df_cleaned['Age_Group'] = None\n",
        "\n",
        "print(df_cleaned[['Age', 'Age_Group']].head())"
      ],
      "metadata": {
        "id": "kA6uR4wj4iSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 16: Categorical Mapping (Encoding)**\n",
        "**Objective:** Machine Learning models don't understand text. Use `.map()` to convert the `Sex` column into numeric values: **'male' -> 0** and **'female' -> 1**."
      ],
      "metadata": {
        "id": "NY6ioTDY47gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Map Sex column to 0 and 1\n",
        "df_cleaned['Sex'] = None\n",
        "\n",
        "print(df_cleaned['Sex'].value_counts())"
      ],
      "metadata": {
        "id": "ajTS3kT448oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 17: Multi-Aggregation Report**\n",
        "**Objective:** Group the data by `Pclass` and `Survived`. For the `Fare` column, calculate the **Mean**, **Min**, and **Max** all in one table using `.agg()`."
      ],
      "metadata": {
        "id": "w1aWJi1t4_aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: GroupBy Pclass/Survived and aggregate Fare (mean, min, max)\n",
        "fare_stats = None\n",
        "\n",
        "print(fare_stats)"
      ],
      "metadata": {
        "id": "Hz8R_KZG5AQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 18: Data Merging (Lookup Table)**\n",
        "**Objective:** Create a new DataFrame called `port_names` with two columns: `Embarked` (C, Q, S) and `Full_Port_Name` (Cherbourg, Queenstown, Southampton). Perform a **Left Merge** to add the full port names to your main DataFrame."
      ],
      "metadata": {
        "id": "Z8bAm4f35Di2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create port_names DF and merge with df_cleaned\n",
        "port_names = pd.DataFrame({\n",
        "    'Embarked': ['C', 'Q', 'S'],\n",
        "    'Full_Port_Name': ['Cherbourg', 'Queenstown', 'Southampton']\n",
        "})\n",
        "\n",
        "df_merged = None\n",
        "\n",
        "print(df_merged[['Embarked', 'Full_Port_Name']].head())"
      ],
      "metadata": {
        "id": "ZKGTeJvO5Erg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 19: String Transformation (Title Extraction)**\n",
        "**Objective:** In the `Name` column, titles like (Mr, Mrs, Miss) are included. Use `.apply()` or string methods to extract the **Title** from each name and create a new column `Title`.\n",
        "*Example: \"Braund, Mr. Owen Harris\" -> \"Mr\"*"
      ],
      "metadata": {
        "id": "lf4Ivwq85ckD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Extract titles from the Name column\n",
        "df_cleaned['Title'] = None\n",
        "\n",
        "print(df_cleaned['Title'].unique())"
      ],
      "metadata": {
        "id": "tIdXMAKv5d3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 20: Sorting & Final Export**\n",
        "**Objective:** Sort the final cleaned DataFrame by `Fare` (Descending) and then by `Age` (Ascending). After sorting, save the first 50 rows into a variable named `top_50_report`."
      ],
      "metadata": {
        "id": "6hz3lcL25hoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Sort and slice the top 50\n",
        "top_50_report = None\n",
        "\n",
        "print(\"Top 5 Passengers in Report:\")\n",
        "display(top_50_report.head())"
      ],
      "metadata": {
        "id": "QRTPq_SI5iyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# üèÅ Conclusion\n",
        "\n",
        "# üèõÔ∏è [ AI Club - University of Jeddah ] üèõÔ∏è\n",
        "\n",
        "# Machine Learning Foundations: The Ultimate Challenge üèÜ\n",
        "\n",
        "\n",
        "| Platform | Link/Handle |\n",
        "| :--- | :--- |\n",
        "| **Twitter (X)** üê¶ | [@AIClubJeddah](https://x.com/AIClubJeddah) |\n",
        "| **Email** üìß | [aiclub-uj@aiclub-uj.com](mailto:aiclub-uj@aiclub-uj.com) |\n",
        "\n"
      ],
      "metadata": {
        "id": "G0lv4M3n7Rym"
      }
    }
  ]
}